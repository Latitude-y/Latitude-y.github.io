<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Node2Vec学习笔记</title>
      <link href="/2022/06/21/Node2vec/"/>
      <url>/2022/06/21/Node2vec/</url>
      
        <content type="html"><![CDATA[<h1 id="Node2vec-Scalable-Feature-Learning-for-Networks"><a href="#Node2vec-Scalable-Feature-Learning-for-Networks" class="headerlink" title="Node2vec:Scalable Feature Learning for Networks"></a><a href="https://dl.acm.org/doi/abs/10.1145/2939672.2939754">Node2vec:Scalable Feature Learning for Networks</a></h1><blockquote><h2 id="论文的研究背景"><a href="#论文的研究背景" class="headerlink" title="论文的研究背景"></a>论文的研究背景</h2><blockquote><h3 id="本论文解决什么问题？（能否通过一个示例来说明拟解决的问题）"><a href="#本论文解决什么问题？（能否通过一个示例来说明拟解决的问题）" class="headerlink" title="本论文解决什么问题？（能否通过一个示例来说明拟解决的问题）"></a>本论文解决什么问题？（能否通过一个示例来说明拟解决的问题）</h3></blockquote></blockquote><p>在复杂网络领域主要有两类任务：网络节点分类和链路预测。在完成这两类问题之前首要解决的任务就是网络节点的嵌入。本篇论文要解决的问题就是如何设计一种既能保持节点邻居信息和体现网络信息而且又容易训练的模型来实现网络嵌入<br>比如将一篇文章构造成的词共现网络中，如果需要实现关键词提取或摘要提取等任务，则需要对该词共现网络进行节点分类以及链路预测，在此之前，首先就需要将该词共现网络中的节点信息向量化，成为词向量，也就是实现节点嵌入，再通过网络的嵌入信息完成更多下游任务。</p><blockquote><blockquote><h3 id="关于该问题，目前的相关工作有哪些？这些相关工作有何优缺点？（综述相关工作）"><a href="#关于该问题，目前的相关工作有哪些？这些相关工作有何优缺点？（综述相关工作）" class="headerlink" title="关于该问题，目前的相关工作有哪些？这些相关工作有何优缺点？（综述相关工作）"></a>关于该问题，目前的相关工作有哪些？这些相关工作有何优缺点？（综述相关工作）</h3></blockquote></blockquote><ul><li>手工提取特征的方式。特征需要依赖人手工定义，所以需要特定领域内专业人士来完成，而且手工提取特征步骤繁琐，对不同任务泛化能力差。</li><li>解优化函数的方式学习网络的表示特征。该方法面临一个计算效率和准确度的平衡问题，无法兼顾两者。</li><li>传统的降维方法（基于线性或非线性的降维技术）。有一定的效果，缺点是会涉及矩阵分解，运算量大，同时准确率也不高，而且有些方法只是针对特定的任务才有效果。</li></ul><blockquote><h2 id="论文的主要研究内容"><a href="#论文的主要研究内容" class="headerlink" title="论文的主要研究内容"></a>论文的主要研究内容</h2><blockquote><h3 id="针对已有工作的不足之处，本文提出了什么方法？（该方法为何有效？）该方法的基本思路是什么？主要创新点在哪？"><a href="#针对已有工作的不足之处，本文提出了什么方法？（该方法为何有效？）该方法的基本思路是什么？主要创新点在哪？" class="headerlink" title="针对已有工作的不足之处，本文提出了什么方法？（该方法为何有效？）该方法的基本思路是什么？主要创新点在哪？"></a>针对已有工作的不足之处，本文提出了什么方法？（该方法为何有效？）该方法的基本思路是什么？主要创新点在哪？</h3></blockquote></blockquote><p><strong>本文针对过去工作的不足之处，主要提出了以下三点优化：</strong></p><ul><li>优化目标函数，给定一个顶点，令其近邻顶点出现的概率最大；</li><li>提出有偏的随机游走路径采样策略；</li><li>使用Alias Sample方法进行顶点采样</li></ul><p>其中第二点，使用有偏的路径采样策略是本篇论文的核心思想，该方法引入两个超参数p和q来控制随机游走的策略。q越小，遍历到远处节点的概率越高，图的遍历越倾向于DFS，同时越趋向于表示图的同质性；p越小，图的遍历越倾向于BFS，越趋向于表示图的结构性。其中随机游走是p&#x3D;1，q&#x3D;1的一种特殊情况。</p><p><strong>本文的创新点主要有以下两点:</strong></p><ul><li>提出一种新的网络节点嵌入算法，其拓展性更好；</li><li>设计了有偏的随机游走算法，通过p，q等超参调节不同的游走情况，使其更加灵活的探索了网络的同质性或者结构性等信息。</li></ul><blockquote><blockquote><h3 id="阐述本文提出方法的技术细节"><a href="#阐述本文提出方法的技术细节" class="headerlink" title="阐述本文提出方法的技术细节"></a>阐述本文提出方法的技术细节</h3></blockquote></blockquote><p><strong>1. 优化目标函数</strong><br>论文将Skip-gram模型扩展到网络中来，优化以下目标函数：<br><img src="/pictures/Node2vec/1.png" alt="1"><br>为了使优化问题更容易处理，文章做了以下两个标准假设：</p><ul><li><strong>条件独立性假设</strong><br>条件独立给定一个顶点，其近邻顶点出现的概率与近邻集合中的其他顶点无关，得到以下公式：<br><img src="/pictures/Node2vec/2.png" alt="2"></li><li><strong>特征空间对称性假设</strong><br>源顶点和近邻顶点在特征空间中具有对称性，不管该顶点是源顶点还是近邻点Embedding表达是一样的，得到以下公式：<br><img src="/pictures/Node2vec/3.png" alt="3"><br>根据以上两个标准假设，原公式最终优化为以下目标函数：<br><img src="/pictures/Node2vec/4.png" alt="4"></li></ul><p><strong>2. 路径采样策略</strong><br>网络结构中存在两种性质，一是同质性，比如u和s1~s4处于同一个社区中，相连的边越少，权重越大，则同质性越强；二是结构性，比如u和s6的关系，它们虽然不接近，但是在彼此的社区中的角色类似，都是扮演中心节点的角色。相对应的，广度优先搜索BFS更适合探索网络的同质性，深度优先搜索DFS更适合探索网络的结构性。如下图所示。<br><img src="/pictures/Node2vec/5.png" alt="5"><br>Node2vec通过对参数的调节，可以在BFS和DFS之间进行权衡，同时探索网络的同质性和结构性。<br>在论文中，设定G&#x3D;（V，E）作为图，其中V为图的节点，E为图的边。对于任意一个节点u∈V，模拟一个长度为l的随机游走。设定ci为随机游走的第i个节点，其中第i个节点ci通过以下概率分布出现：<br><img src="/pictures/Node2vec/6.png" alt="6"><br>其中π_vx节点v和节点x的非归一化转移概率，Z为归一化常数。<br>文章通过设定π_vx&#x3D;α_pq (t,x)*w_vx来调整节点之间的转移概率，其中：<br><img src="/pictures/Node2vec/7.png" alt="7"><br>其中d_tx表示节点t和节点x之间的最短距离，__p为返回参数（Return parameter）__，__q为进出参数(In-out parameter)__。<br>由以上公式可知，q越小，遍历到远处节点的概率越高，图的遍历越倾向于DFS，同时越趋向于表示图的同质性；p越小，节点返回t的概率越大，图的遍历越倾向于BFS，越趋向于表示图的结构性。因此可以设置参数p、q的值来权衡图嵌入表达结果的倾向性。示例如下图所示。<br><img src="/pictures/Node2vec/8.png" alt="8">  </p><blockquote><h2 id="论文的实验结果"><a href="#论文的实验结果" class="headerlink" title="论文的实验结果"></a>论文的实验结果</h2><blockquote><h3 id="阐述本文的实验内容"><a href="#阐述本文的实验内容" class="headerlink" title="阐述本文的实验内容"></a>阐述本文的实验内容</h3></blockquote></blockquote><ul><li><p><strong>实验一:</strong> 将小说《悲惨世界》中的角色构建成含有77个节点和254条边的网络，设置不同的参数，使用Node2vec对图节点进行嵌入，验证Node2vec可以符合网络同质性和结构性的节点嵌入。<br>下图中顶部那副图对应p&#x3D;1,q&#x3D;0.5的情况。即p&#x3D;1,q&#x3D;0.5时算出每个节点的特征表示，然后根据特征表示进行聚类。在这个设置下，Node2vec发现了小说中经常互动的角色集群。<br>为了发现哪些节点具有相同的结构角色，使用相同的网络，设置p&#x3D;1,q&#x3D;2，使用Node2vec获取节点特征，然后根据获得的特征对节点进行聚类，结果如表图3底部所示。蓝色节点代表了小说中不同次要情节之间的桥梁，他们具有相似的结构角色。<br><img src="/pictures/Node2vec/9.png" alt="9">  </p></li><li><p><strong>实验二:</strong> 多标签分类。在多标签分类设置中，每个节点都从有限集L中分配一个或多个标签。在训练阶段，观察一定比例的节点及其所有标签。实验任务是预测剩余节点的标签。实验结果如下图所示，可见在多标签分类任务中Node2vec表现最好。<br>对比算法：Spectral Clustering、Deep Walk、LINE<br>使用的数据集：BlogCatalog(社交博客网站)、Protein-Protein Interactions(PPI)(蛋白质作用网络)、Wikipedia(词共现网络)<br><img src="/pictures/Node2vec/10.png" alt="10"><br><img src="/pictures/Node2vec/15.png" alt="15"> </p></li><li><p><strong>实验三:</strong> 参数灵敏度分析。使用标记数据和未标记数据之间的50-50分割来检查选择不同的参数如何影响Node2vec在BlogCatalog数据集上的性能。由下图可见，Node2vec的性能随着出入参数p和返回参数q的减少而提高，其他参数如d，r，l，k均能一定程度上提升Node2vec的性能，但有上限。<br><img src="/pictures/Node2vec/11.png" alt="11"> </p></li><li><p><strong>实验四:</strong> 扰动分析。文章分析了在信息有所缺失的网络情况下Node2vec的性能。第一种情况是在网络中随机选择缺失边，测试Node2vec随着网络中缺失边数量的增加性能的变化情况。第二种情况是在网络中随机选择节点对之间的噪声边缘，测试Node2vec随着网络中噪声边的增加性能的变化情况。如下图可见，随着数据集中缺失边越来越多，性能是越来越差的，但是总体来说下降斜率比较平缓；随着噪声越多，性能越差，但其下降速率在不断变慢。<br><img src="/pictures/Node2vec/12.png" alt="12"> </p></li><li><p><strong>实验五:</strong> 可扩展性分析。使用Node2vec学习节点表示，将Node2vec用于Erdos-Renyi图，设置Erdos-Renyi图的默认参数值从100增加到1000000个节点，平均度数为10，测试Node2vec的可扩展性。如下图可见，图的节点从100个增加到1000000个，Node2vec的时间复杂度在线性增加。<br><img src="/pictures/Node2vec/13.png" alt="13"> </p></li><li><p><strong>实验六:</strong> 链路预测。在链接预测中，文章使用一个删除了部分边的网络，并且预测这些丢失的边。文章按如下方式生成带标签的边的数据集：为了生成正样本，从网络中移除50%随机选择的边，同时确保在移除边后获得的剩余网络是连接的；为了生成负样本，从网络中随机抽取相同数量的节点对，这些节点对没有相互连接的边。由于之前没有将任何特征学习算法用于链路预测，因此文章还根据一些在链接预测中取得良好性能的流行启发式分数来评估Node2vec。如下图可见，Node2vec在arXiv数据集上取得了最好效果，相比于启发式方法中最好的Adamic-Adar提高了12.6%，并且Node2vec在所有网络中都优于DeepWalk和LINE。<br><img src="/pictures/Node2vec/14.png" alt="14"></p></li></ul><blockquote><blockquote><h3 id="本文方法的有效性是如何通过实验进行验证的？"><a href="#本文方法的有效性是如何通过实验进行验证的？" class="headerlink" title="本文方法的有效性是如何通过实验进行验证的？"></a>本文方法的有效性是如何通过实验进行验证的？</h3></blockquote></blockquote><p>在实验二多标签分类和实验六链路预测中，论文选取了三个比较主流的节点嵌入算法在三个不同领域的大型数据集上进行实验对比，在相同的实验条件下，均可得出Node2vec算法相较于其他算法的优越性。除此之外，论文还测试了不同参数对Node2vec算法的影响，并且考虑到网络本身的情况，比如缺失边以及噪声边的情况下，Node2vec的效能变化。总之在一系列的实验下，通过对比Node2vec相较于其他算法的优势以及对Node2vec本身结构的实验研究，十分全面的说明了Node2vec的有效性。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>MarkDown学习</title>
      <link href="/2022/06/17/MarkDown/"/>
      <url>/2022/06/17/MarkDown/</url>
      
        <content type="html"><![CDATA[<h1 id="一级标题"><a href="#一级标题" class="headerlink" title="#一级标题"></a>#一级标题</h1><p>=&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;一级标题分割线</p><h2 id="二级标题"><a href="#二级标题" class="headerlink" title="##二级标题"></a>##二级标题</h2><hr><p>-——————二级标题分割线</p><h3 id="三级标题"><a href="#三级标题" class="headerlink" title="###三级标题"></a>###三级标题</h3><h4 id="四级标题"><a href="#四级标题" class="headerlink" title="####四级标题"></a>####四级标题</h4><h5 id="五级标题"><a href="#五级标题" class="headerlink" title="#####五级标题"></a>#####五级标题</h5><h6 id="六级标题"><a href="#六级标题" class="headerlink" title="######六级标题"></a>######六级标题</h6><hr><p><em>*斜体文本*</em><br><em>_斜体文本_</em></p><hr><p><strong>**粗体文本**</strong><br><strong>__粗体文本__</strong></p><hr><p><em><strong>***斜粗体文本***</strong></em><br><em><strong>___斜粗体文本___</strong></em></p><hr><p>~~~~删除线~~~~<br><u>&lt;u&gt;下划线&lt;&#x2F;u&gt;</u></p><hr><p>这是脚注[^foot]<br><img src="/pictures/%E8%84%9A%E6%B3%A8.png" alt="脚注" title="脚注"><br>[^foot]:脚注</p><hr><p>###无序列表</p><ul><li>+ 第一项，+号后面要加空格</li></ul><ul><li>* 第二项，要加空格</li></ul><ul><li>- 第三项，要加空格，+,-,*都可以</li></ul><p>###有序列表</p><ol><li>第一项</li><li>第二项</li><li>第三项，要加空格</li></ol><p>###嵌套列表</p><ol><li>1<ul><li>1.1</li><li>1.2</li><li>1.3</li></ul></li><li>2<ul><li>2.1</li></ul><ul><li>2.2</li></ul><ul><li>二级列表加四个空格</li></ul></li></ol><hr><blockquote><p>&gt;最外层嵌套</p><blockquote><p>&gt;&gt;第一层嵌套</p><blockquote><p>&gt;&gt;&gt;第二层嵌套</p><blockquote><p>&gt;&gt;&gt;&gt;第三层嵌套</p></blockquote></blockquote></blockquote></blockquote><ul><li>*列表加嵌套<br> &gt;最外层 (加四个空格缩进或一个tab键)</li></ul><hr><p> <code>print()</code>函数</p><p> 代码函数或者片段使用反引号 &#96;&#96; 将代码包起来</p><pre><code>    public static Boolean equal(int[] nums)&#123;    int sum=0;    for(int s:nums)&#123;        sum=sum+s;    &#125;    if(sum%2!=0)&#123;        return false;    &#125;    int sum2=sum/2;    int[] dp=new int[sum2+1];    for(int i=0;i&lt;nums.length;i++)&#123;        for(int j=sum2;j&gt;=nums[i];j--)&#123;            int a=dp[j];            int b=dp[j-nums[i]]+nums[i];            dp[j]=Math.max(a,b);            if(dp[j]==sum2)&#123;                return true;            &#125;        &#125;    &#125;    return false;&#125;</code></pre><p>代码块可以给一个tab键然后开始放入代码块<br>或者三个反引号 ```    ```</p><hr><p>这是一个<a href="https://www.baidu.com/">链接</a><br>格式：<br>[ 链接名称 ]  (链接地址)</p><p><a href="https://www.baidu.com/">https://www.baidu.com</a><br>&lt;直接使用链接地址&gt;</p><hr><p>###放图片<br><img src="/pictures/au3.png" alt="C型" title="C"></p><p>![图片的代替文字]（图片url “图片标题”）</p><p><img src="/pictures/au3.png" width="70%" height="70%"></img><br>可以使用 &lt;</template>img src&#x3D;”url” width&#x3D;”” height&#x3D;”” &gt;方式指定图片大小</p><hr><p>###表格</p><table><thead><tr><th>表头</th><th>表头</th></tr></thead><tbody><tr><td>单元格</td><td>单元格</td></tr><tr><td>单元格</td><td>单元格</td></tr></tbody></table>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>勇士总冠军！库里FMVP！</title>
      <link href="/2022/06/17/FMVP/"/>
      <url>/2022/06/17/FMVP/</url>
      
        <content type="html"><![CDATA[<p><img src="/pictures/FMVP1.jpg" alt="FMVP1" title="FMVP1"><br><img src="/pictures/FMVP2.jpg" alt="FMVP2" title="FMVP2"><br><img src="/pictures/FMVP3.jpg" alt="FMVP3" title="FMVP3"><br><img src="/pictures/FMVP4.jpg" alt="FMVP4" title="FMVP4"><br><img src="/pictures/FMVP5.jpg" alt="FMVP5" title="FMVP5"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>来自M78星云的光之巨人的传说</title>
      <link href="/2022/05/13/%E5%A5%A5%E7%89%B9%E6%9B%BC/"/>
      <url>/2022/05/13/%E5%A5%A5%E7%89%B9%E6%9B%BC/</url>
      
        <content type="html"><![CDATA[<p><strong>他是来自M78星云的光之巨人，为了追捕逃亡的宇宙怪兽百慕拉而来到地球。在龙森湖上空追击百慕拉时，他不慎与科学特别搜查队队员早田进所乘的战斗机相撞，导致早田坠机死亡。为了弥补自己的过失、以及挽救早田进的生命，奥特曼将自己的生命给予了早田，与之一心同体使其复活。之后，奥特曼与早田一起，为保卫地球而与众多凶暴的怪兽和邪恶的宇宙人展开了激烈的战斗。</strong></p><blockquote><h2 id="奥特曼的三种形态"><a href="#奥特曼的三种形态" class="headerlink" title="奥特曼的三种形态"></a>奥特曼的三种形态</h2></blockquote><blockquote><blockquote><h3 id="A型"><a href="#A型" class="headerlink" title="A型"></a>A型</h3></blockquote></blockquote><p><strong>奥特曼的初始皮套，由潜水服改造而来。第一代面具为了体现奥特曼嘴部的活动，而用合成橡胶裹在了面罩上使得演员能活动嘴巴。但后来圆谷认识到即使做了这些努力嘴部活动效果依然不明显还会导致面部变的凹凸不平，因此之后的面罩不再采用A型的制作方法。</strong><br><strong>在2006年剧场版《梦比优斯·奥特曼与奥特兄弟》和2008年的《大决战！超奥特8兄弟》中，出于情怀致敬的目的，特地让奥特曼以A型脸的形象登场。</strong></p><blockquote><blockquote><h4 id="具体特征"><a href="#具体特征" class="headerlink" title="具体特征"></a>具体特征</h4></blockquote></blockquote><ol><li>脸部崩坏</li><li>嘴部能够轻微地张开</li><li>基本上看不出胸肌</li><li>足部脚尖微微上翘</li></ol><blockquote><blockquote><h4 id="TV登场时段：第1话-第13话"><a href="#TV登场时段：第1话-第13话" class="headerlink" title="TV登场时段：第1话~第13话"></a>TV登场时段：第1话~第13话</h4></blockquote></blockquote><p><img src="/pictures/au1.png" alt="A" title="A"></p><blockquote><blockquote><h3 id="B型"><a href="#B型" class="headerlink" title="B型"></a>B型</h3></blockquote></blockquote><p><strong>这个皮套是因为A型皮套老化严重所以才被制作出来的，各方面（面部，胸前等）十分紧凑。B型皮套于1970年失窃，而并非在拍摄途中丢失。</strong><br><strong>在2009年剧场版《宇宙英雄之超银河传说》中，出于情怀致敬的目的，以及和佐菲、杰克等奥特战士作区分，特地让奥特曼再度以B型脸的形象登场出现。</strong></p><blockquote><blockquote><h4 id="具体特征："><a href="#具体特征：" class="headerlink" title="具体特征："></a>具体特征：</h4></blockquote></blockquote><ol><li>嘴型在三种皮套设计中最小</li><li>身上的花纹比较紧凑</li><li>足尖上翘很厉害</li></ol><blockquote><blockquote><h4 id="TV登场时段：第14话-第29话"><a href="#TV登场时段：第14话-第29话" class="headerlink" title="TV登场时段：第14话~第29话"></a>TV登场时段：第14话~第29话</h4></blockquote></blockquote><p><img src="/pictures/au2.png" alt="B" title="B"></p><blockquote><blockquote><h3 id="C型"><a href="#C型" class="headerlink" title="C型"></a>C型</h3></blockquote></blockquote><p><strong>作为奥特曼标准形象的C型，此皮套被制作出来的理由并非是因为B型皮套失窃（B型皮套失窃的时间点并不是在拍摄期间），而是为了改进B型的形象。奥特曼在后续的奥特系列作品中登场时，使用最多的也是C型脸形象。</strong></p><blockquote><blockquote><h4 id="具体特征：-1"><a href="#具体特征：-1" class="headerlink" title="具体特征："></a>具体特征：</h4></blockquote></blockquote><ol><li>身上的花纹结合了A型和B型的优点</li><li>胸肌十分的突出</li><li>足尖无上翘</li></ol><blockquote><blockquote><h4 id="TV登场时段：第30话-第39话"><a href="#TV登场时段：第30话-第39话" class="headerlink" title="TV登场时段：第30话~第39话"></a>TV登场时段：第30话~第39话</h4></blockquote></blockquote><p><img src="/pictures/au3.png" alt="C" title="C"></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
